{
 "metadata": {
  "name": "",
  "signature": "sha256:905776f75c433b4c38462719b4e89e356f64d2d51b93c1d074c674bccd63b447"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/python\n",
      "import sys\n",
      "import pickle\n",
      "sys.path.append(\"../tools/\")\n",
      "# These functions were provided by Udacity\n",
      "from feature_format import featureFormat, targetFeatureSplit\n",
      "from tester import dump_classifier_and_data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features_list = ['poi', 'salary', 'bonus', 'long_term_incentive', \\\n",
      "                 'deferred_income', 'deferral_payments', 'loan_advances', \\\n",
      "                 'other', 'expenses', 'director_fees', 'restricted_stock', \\\n",
      "                 'exercised_stock_options', 'restricted_stock_deferred', \\\n",
      "                 'total_payments', 'total_stock_value', \\\n",
      "                 'from_poi_to_this_person', 'from_this_person_to_poi', \\\n",
      "                 'shared_receipt_with_poi', 'from_messages', 'to_messages']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def FeatureSelection(data_dict, features_list):                \n",
      "    # Convert dictionary to numpy array, converts NaN to 0.0                  \n",
      "    data = featureFormat(data_dict, features_list, \\\n",
      "                         sort_keys = True, remove_all_zeroes = False)\n",
      "    # Separate into labels = 'poi' and features = rest of features_list\n",
      "    labels, features = targetFeatureSplit(data)\n",
      "    \n",
      "    from sklearn.feature_selection import RFECV \n",
      "    # Recursive Feature Elimination with Cross Validation\n",
      "    from sklearn.svm import SVC\n",
      "    # Support Vector Classifier to estimate fit coefficients for each feature\n",
      "    from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "    # cross validation maintain roughly equal number of POIs in each split\n",
      "    \n",
      "    ### Create Estimator \n",
      "    # which will update the coefficients with each iteration\n",
      "    # class weight is set to auto because of unbalanced data classes\n",
      "    # weight will be inversely proportional to class size\n",
      "    svc = SVC(kernel='linear', class_weight='auto', random_state=42)\n",
      "    ############## Scale features ######################\n",
      "    # SVC algorithm requires use scaled features\n",
      "    # missing values are coded 0.0, so MinMax will preserve those zero values\n",
      "    from sklearn.preprocessing import MinMaxScaler\n",
      "    scaler = MinMaxScaler()\n",
      "    features = scaler.fit_transform(features)\n",
      "    \n",
      "    ### Select cross-validation method\n",
      "    # StratifiedShuffleSplit keeps roughly the same number of POIs in each split \n",
      "    sss = StratifiedShuffleSplit(labels, 100, test_size=0.3, random_state=42)\n",
      "    ### Select evaluation metric\n",
      "    # Evaluate model using f1 = 2 * (precision * recall) / (precision + recall)\n",
      "    # Model should be able to predict POIs, which are a small percentage of cases\n",
      "    metric = 'f1'\n",
      "    # run the feature eliminater\n",
      "    rfecv = RFECV(estimator=svc, cv=sss, scoring=metric, step=1)\n",
      "    rfecv = rfecv.fit(features, labels)\n",
      "    return selected_features, F1_score\n",
      "    \n",
      "features_list, initial_F1 = FeatureSelection(data_dict, features_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimal number of features is 16\n",
        "Features selected by recursive feature elimination with cross validation:\n",
        "F1 score from optimal features: 0.292\n",
        "['salary', 'bonus', 'long_term_incentive', 'deferred_income', 'deferral_payments', 'expenses', 'director_fees', 'restricted_stock', 'exercised_stock_options', 'restricted_stock_deferred', 'total_stock_value', 'from_poi_to_this_person', 'from_this_person_to_poi', 'shared_receipt_with_poi', 'from_messages', 'to_messages']\n",
        "Features eliminated:\n",
        "['loan_advances', 'other', 'total_payments']\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print features_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['poi', 'salary', 'bonus', 'long_term_incentive', 'deferred_income', 'deferral_payments', 'expenses', 'director_fees', 'restricted_stock', 'exercised_stock_options', 'restricted_stock_deferred', 'total_stock_value', 'from_poi_to_this_person', 'from_this_person_to_poi', 'shared_receipt_with_poi', 'from_messages', 'to_messages']\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "####################################################################\n",
      "### Task 3: Create new feature(s)\n",
      "### Give emails to/from pois as a proportion of total emails\n",
      "### Create new features as keys in data_dict\n",
      "for person in data_dict.keys():\n",
      "    to_poi = float(data_dict[person]['from_this_person_to_poi'])\n",
      "    to_all = float(data_dict[person]['from_messages'])\n",
      "    if to_all > 0:\n",
      "        data_dict[person]['fraction_to_poi'] = to_poi / to_all\n",
      "    else:\n",
      "        data_dict[person]['fraction_to_poi'] = 0\n",
      "    from_poi = float(data_dict[person]['from_poi_to_this_person'])\n",
      "    from_all = float(data_dict[person]['to_messages'])\n",
      "    if from_all > 0:\n",
      "        data_dict[person]['fraction_from_poi'] = from_poi / from_all\n",
      "    else:\n",
      "        data_dict[person]['fraction_from_poi'] = 0\n",
      "\n",
      "############# Evaluate new features\n",
      "### Add new feature to features_list\n",
      "features_list.extend(['fraction_to_poi', 'fraction_from_poi'])\n",
      "\n",
      "features_list, second_F1 = FeatureSelection(data_dict, features_list)\n",
      "\n",
      "#### keep the engineered features added to data_dict\n",
      "my_dataset = data_dict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Optimal number of features is 4\n",
        "Features selected by recursive feature elimination with cross validation:\n",
        "F1 score from optimal features: 0.332\n",
        "['expenses', 'exercised_stock_options', 'shared_receipt_with_poi', 'fraction_to_poi']\n",
        "Features eliminated:\n",
        "['salary', 'bonus', 'long_term_incentive', 'deferred_income', 'deferral_payments', 'director_fees', 'restricted_stock', 'restricted_stock_deferred', 'total_stock_value', 'from_poi_to_this_person', 'from_this_person_to_poi', 'from_messages', 'to_messages', 'fraction_from_poi']\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print features_list"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['poi', 'expenses', 'exercised_stock_options', 'shared_receipt_with_poi', 'fraction_to_poi']\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Task 4: Try a varity of classifiers\n",
      "### Please name your classifier clf for easy export below.\n",
      "### Note that if you want to do PCA or other multi-stage operations,\n",
      "### you'll need to use Pipelines. For more info:\n",
      "### http://scikit-learn.org/stable/modules/pipeline.html\n",
      "\n",
      "##### Random Forest\n",
      "from sklearn.ensemble import RandomForestClassifier\n",
      "rf = RandomForestClassifier(class_weight='auto', random_state=42)\n",
      "from time import time\n",
      "from tester import test_classifier\n",
      "t0 = time()\n",
      "test_classifier(rf, data_dict, features_list, folds = 100)\n",
      "print(\"Random forest fitting time: %rs\" % round(time()-t0, 3))\n",
      "\n",
      "###### Adaboost\n",
      "from sklearn.ensemble import AdaBoostClassifier\n",
      "ab = AdaBoostClassifier(random_state=42)\n",
      "t0 = time()\n",
      "test_classifier(ab, data_dict, features_list, folds = 100)\n",
      "print(\"AdaBoost fitting time: %rs\" % round(time()-t0, 3))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "RandomForestClassifier(bootstrap=True, class_weight='auto', criterion='gini',\n",
        "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=42, verbose=0, warm_start=False)\n",
        "\tAccuracy: 0.84857\tPrecision: 0.44340\tRecall: 0.23500\tF1: 0.30719\tF2: 0.25938\n",
        "\tTotal predictions: 1400\tTrue positives:   47\tFalse positives:   59\tFalse negatives:  153\tTrue negatives: 1141\n",
        "\n",
        "Random forest fitting time: 1.048s\n",
        "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
        "          learning_rate=1.0, n_estimators=50, random_state=42)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tAccuracy: 0.87000\tPrecision: 0.55357\tRecall: 0.46500\tF1: 0.50543\tF2: 0.48037\n",
        "\tTotal predictions: 1400\tTrue positives:   93\tFalse positives:   75\tFalse negatives:  107\tTrue negatives: 1125\n",
        "\n",
        "AdaBoost fitting time: 5.874s\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "### Task 5: Tune your classifier to achieve better than .3 precision and recall \n",
      "### using our testing script. Check the tester.py script in the final project\n",
      "### folder for details on the evaluation method, especially the test_classifier\n",
      "### function. Because of the small size of the dataset, the script uses\n",
      "### stratified shuffle split cross validation. For more info: \n",
      "### http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.StratifiedShuffleSplit.html\n",
      "\n",
      "# Convert dictionary to numpy array, converts NaN to 0.0                  \n",
      "data = featureFormat(data_dict, features_list, \\\n",
      "                     sort_keys = True, remove_all_zeroes = False)\n",
      "# Separate into labels = 'poi' and features = rest of features_list\n",
      "labels, features = targetFeatureSplit(data)\n",
      "\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "rf_params = {'max_features': range(1,5), 'n_estimators': range(10, 101, 10)}\n",
      "from sklearn.cross_validation import StratifiedShuffleSplit\n",
      "sss = StratifiedShuffleSplit(labels, 100, test_size=0.3, random_state=42)\n",
      "metric = 'f1'\n",
      "# use same estimator (rf, random forest) as above; add suffix t for tuned\n",
      "t0 = time()\n",
      "rft = GridSearchCV(rf, rf_params, scoring=metric, cv=sss)\n",
      "print(\"Random Forest tuning: %r\" % round(time()-t0, 3))\n",
      "t0 = time()\n",
      "rft = rft.fit(features, labels)\n",
      "print(\"Random forest fitting time: %rs\" % round(time()-t0, 3))\n",
      "rf = rft.best_estimator_\n",
      "t0 = time()\n",
      "test_classifier(rf, data_dict, features_list, folds = 100)\n",
      "print(\"Random Forest evaluation time: %rs\" % round(time()-t0, 3))\n",
      "\n",
      "from sklearn.tree import DecisionTreeClassifier\n",
      "dt = []\n",
      "for i in range(5):\n",
      "    dt.append(DecisionTreeClassifier(max_depth=(i+1)))\n",
      "ab_params = {'base_estimator': dt, 'n_estimators': range(50, 101, 10)}\n",
      "t0 = time()\n",
      "abt = GridSearchCV(ab, ab_params, scoring=metric, cv=sss)\n",
      "print(\"AdaBoost tuning: %r\" % round(time()-t0, 3))\n",
      "t0 = time()\n",
      "abt = abt.fit(features, labels)\n",
      "print(\"AdaBoost fitting time: %rs\" % round(time()-t0, 3))\n",
      "ab = abt.best_estimator_\n",
      "t0 = time()\n",
      "test_classifier(ab, data_dict, features_list, folds = 100)\n",
      "print(\"AdaBoost evaluation time: %rs\" % round(time()-t0, 3))\n",
      "\n",
      "### Select tuned adaboost as best classifier\n",
      "clf = ab\n",
      "    \n",
      "### Task 6: Dump your classifier, dataset, and features_list so anyone can\n",
      "### check your results. You do not need to change anything below, but make sure\n",
      "### that the version of poi_id.py that you submit can be run on its own and\n",
      "### generates the necessary .pkl files for validating your results.\n",
      "\n",
      "dump_classifier_and_data(clf, my_dataset, features_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Random Forest tuning: 0.0\n",
        "Random forest fitting time: 205.025s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "RandomForestClassifier(bootstrap=True, class_weight='auto', criterion='gini',\n",
        "            max_depth=None, max_features=4, max_leaf_nodes=None,\n",
        "            min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
        "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tAccuracy: 0.84214\tPrecision: 0.42336\tRecall: 0.29000\tF1: 0.34421\tF2: 0.30950\n",
        "\tTotal predictions: 1400\tTrue positives:   58\tFalse positives:   79\tFalse negatives:  142\tTrue negatives: 1121\n",
        "\n",
        "Random Forest evaluation time: 9.36s\n",
        "AdaBoost tuning: 0.0\n",
        "AdaBoost fitting time: 208.453s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "AdaBoostClassifier(algorithm='SAMME.R',\n",
        "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
        "            max_features=None, max_leaf_nodes=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
        "            random_state=None, splitter='best'),\n",
        "          learning_rate=1.0, n_estimators=70, random_state=42)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "\tAccuracy: 0.85786\tPrecision: 0.50279\tRecall: 0.45000\tF1: 0.47493\tF2: 0.45965\n",
        "\tTotal predictions: 1400\tTrue positives:   90\tFalse positives:   89\tFalse negatives:  110\tTrue negatives: 1111\n",
        "\n",
        "AdaBoost evaluation time: 8.208s\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dump_classifier_and_data(clf, my_dataset, features_list)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    }
   ],
   "metadata": {}
  }
 ]
}